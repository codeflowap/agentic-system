
The following guides will help you build more advanced AI Agents:

<CardGroup>
  <Card title="Adding Tools to Agents" href="/concepts/tools" icon="gear">
    Let your Agent act and gather data with tools
  </Card>

  <Card title="Implementing reasoning-based routing" href="/concepts/routers" icon="brain">
    Learn how to dynamically route between agents
  </Card>
</CardGroup>

You can also explore the following examples to see how to use AgentKit in more complex scenarios:

<CardGroup cols={2}>
  <Card title={`Support Agent with "Human in the loop"`} href="https://github.com/inngest/agent-kit/tree/main/examples/support-agent-human-in-the-loop#readme" icon="github">
    This AgentKit example shows how to build a Support Agent Network with a "Human
    in the loop" pattern.
  </Card>

  <Card title="AgentKit SWE-bench" href="https://github.com/inngest/agent-kit/tree/main/examples/swebench#readme" icon="github">
    This AgentKit example uses the SWE-bench dataset to train an agent to solve coding problems. It uses advanced tools to interact with files and codebases.
  </Card>
</CardGroup>


# Code Assistant v2: Complex code analysis
Source: https://agentkit.inngest.com/guided-tour/agentic-workflows

Use AgentKit Tools and Custom Router to add agentic capabilities.

## Overview

Our [Code Assistant v1](/ai-agents-in-practice/ai-workflows), relying on a RAG workflow, had limited capabilities linked to its lack of reasoning.
The second version of our Code Assistant will introduce reasoning capabilities to adapt analysis based on the user's input:

```typescript
const {
  state: { kv },
} = await network.run(
  `Analyze the files/example.ts file by suggesting improvements and documentation.`
);
console.log("Analysis:", kv.get("summary"));

// Analysis: The code analysis suggests several key areas for improvement:

// 1. Type Safety and Structure:
// - Implement strict TypeScript configurations
// - Add explicit return types and interfaces
// - Break down complex functions
// - Follow Single Responsibility Principle
// - Implement proper error handling

// 2. Performance Optimization:
// - Review and optimize critical operations
// ...
```

These agentic (reasoning) capabilities are introduced by the following AgentKit concepts:

* **[Tools](/concepts/tools)**: Enables [Agents](/concepts/agents) to interact with their environment (ex: file system or shared State).
* **[Router](/concepts/router)**: Powers the flow of the conversation between Agents.
* **[Network](/concepts/network)**: Add a shared [State](/concepts/state) to share information between Agents.

Let's learn these concepts in practice.

## Setup

Similarly to the [Code Assistant v1](/ai-agents-in-practice/ai-workflows), perform the following steps to setup your project:

<AccordionGroup>
  <Accordion title="1. Initialize your project" defaultOpen="true">
    <CodeGroup>
      ```bash npm
      npm init
      ```

      ```bash pnpm
      pnpm init
      ```

      ```bash yarn
      yarn init
      ```
    </CodeGroup>
  </Accordion>

  <Accordion title="2. Install the required dependencies">
    <CodeGroup>
      ```bash npm
      npm install @inngest/agent-kit zod
      ```

      ```bash pnpm
      pnpm install @inngest/agent-kit zod
      ```

      ```bash yarn
      yarn add @inngest/agent-kit zod
      ```
    </CodeGroup>
  </Accordion>

  <Accordion title="3. Add TypeScript support">
    <CodeGroup>
      Install the following dev dependencies:

      ```bash npm
      npm install -D tsx @types/node
      ```

      ```bash pnpm
      pnpm install -D tsx @types/node
      ```

      ```bash yarn
      yarn add -D tsx @types/node
      ```
    </CodeGroup>

    And add the following scripts to your `package.json`:

    ```json
    "scripts": {
        "start": "tsx ./index.ts"
    }
    ```
  </Accordion>

  <Accordion title="4. Download the example code file">
    <CodeGroup>
      ```bash
      mkdir files
      cd files
      wget https://raw.githubusercontent.com/inngest/agent-kit/main/examples/code-assistant-agentic/files/example.ts
      cd -
      ```
    </CodeGroup>
  </Accordion>
</AccordionGroup>

You are now set up, let's implement the v2 of our Code Assistant.

## Implementing our Code Assistant v2

### Overview of the agentic workflow

Our Code Assistant v2 introduces reasoning to perform tailored recommendations based on a given code file: refactoring, documentation, etc.

To achieve this behavior, we will need to:

* Create a `code_assistant_agent` Agent that will load a given filename from disk and plan a workflow using the following available [Agents](/concepts/agents):
  * `analysis_agent` that will analyze the code file and suggest improvements
  * `documentation_agent` that will generate documentation for the code file
* Finally, create a `summarization_agent` Agent that will generate a summary of the suggestions made by other agents

{/* _TODO: Add a diagram here_ */}

Compared to our [Code Assistant v1](/ai-agents-in-practice/ai-workflows), this new version does not consist of simple retrieval and generations steps.
Instead, it introduces more flexibility by enabling LLM models to plan actions and select tools to use.

Let's see how to implement the Agents.

### A Network of Agents

Our Code Assistant v2 is composed of 4 Agents collaborating together to analyze a given code file.
Such collaboration is made possible by using a [Network](/concepts/network) to orchestrate the Agents and share [State](/concepts/state) between them.

Unlike the [Code Assistant v1](/ai-agents-in-practice/ai-workflows), the user prompt will be passed to the network instead of an individual Agent:

```typescript
await network.run(
  `Analyze the files/example.ts file by suggesting improvements and documentation.`
);
```

To successfully run, a `Network` relies on:

* A Router to **indicate which Agent should be run next**
* **A shared State**, updated by the Agents' LLM responses and **tool calls**

Let's start by implementing our Agents and registering them into the Network.

### Creating Agents with Tools

<Note>
  Attaching Tools to an Agent helps to:

  * Enrich dynamically the Agent context with dynamic data
  * Store the Agent results in the shared State

  Learn more about [Tools](/concepts/tools).
</Note>

**The Analysis and Documentation Agents**

Our first two analysis Agents are straightforward:

```typescript {5, 10}
import { createAgent } from "@inngest/agent-kit";

const documentationAgent = createAgent({
  name: "documentation_agent",
  system: "You are an expert at generating documentation for code",
});

const analysisAgent = createAgent({
  name: "analysis_agent",
  system: "You are an expert at analyzing code and suggesting improvements",
});
```

Defining task specific LLM calls (Agents) is a great way to make the LLM reasoning more efficient and avoid unnecessary generations.

Our `documentation_agent` and `analysis_agent` are currently stateless and need to be *connected* to the Network by saving their suggestions into the shared State.

For this, we will create our first Tool using [`createTool`](/reference/create-tool):

```typescript {2-6}
const saveSuggestions = createTool({
  name: "save_suggestions",
  description: "Save the suggestions made by other agents into the state",
  parameters: z.object({
    suggestions: z.array(z.string()),
  }),
  handler: async (input, { network }) => {
    const suggestions = network?.state.kv.get("suggestions") || [];
    network?.state.kv.set("suggestions", [
      ...suggestions,
      ...input.suggestions,
    ]);
    return "Suggestions saved!";
  },
});
```

<Tip>
  A Tool is a function that can be called by an Agent.

  The `name`, `description` and `parameters` are used by the Agent to understand what the Tool does and what it expects as input.

  The `handler` is the function that will be called when the Tool is used. `save_suggestions`'s handler relies on the [Network's State `kv` (key-value store)](/reference/state#reading-and-modifying-state-state-kv) API to share information with other Agents.

  Learn more about the [createTool()](/reference/create-tool) API.
</Tip>

The `save_suggestions` Tool is used by both `documentation_agent` and `analysis_agent` to save their suggestions into the shared State:

```typescript {8,14}
import { createAgent } from "@inngest/agent-kit";

// `save_suggestions` definition...

const documentationAgent = createAgent({
  name: "documentation_agent",
  system: "You are an expert at generating documentation for code",
  tools: [saveSuggestions],
});

const analysisAgent = createAgent({
  name: "analysis_agent",
  system: "You are an expert at analyzing code and suggesting improvements",
  tools: [saveSuggestions],
});
```

Our `documentation_agent` and `analysis_agent` are now connected to the Network and will save their suggestions into the shared State.

Let's now create our `code_assistant_agent` that will read the code file from disk and plan the workflow to run.

**The Code Assistant Agent**

Let's jump into the action by looking at the full implementation of our `code_assistant_agent`:

```typescript {3, 18, 31}
const codeAssistantAgent = createAgent({
  name: "code_assistant_agent",
  system: ({ network }) => {
    const agents = Array.from(network?.agents.values() || [])
      .filter(
        (agent) =>
          !["code_assistant_agent", "summarization_agent"].includes(agent.name)
      )
      .map((agent) => `${agent.name} (${agent.system})`);
    return `From a given user request, ONLY perform the following tool calls:
- read the file content
- generate a plan of agents to run from the following list: ${agents.join(", ")}

Answer with "done" when you are finished.`;
  },
  tools: [
    createTool({
      name: "read_file",
      description: "Read a file from the current directory",
      parameters: z.object({
        filename: z.string(),
      }),
      handler: async (input, { network }) => {
        const filePath = join(process.cwd(), `files/${input.filename}`);
        const code = readFileSync(filePath, "utf-8");
        network?.state.kv.set("code", code);
        return "File read!";
      },
    }),
    createTool({
      name: "generate_plan",
      description: "Generate a plan of agents to run",
      parameters: z.object({
        plan: z.array(z.string()),
      }),
      handler: async (input, { network }) => {
        network?.state.kv.set("plan", input.plan);
        return "Plan generated!";
      },
    }),
  ],
});
```

The highlighted lines emphasize three important parts of the `code_assistant_agent`:

* The [`system` property](/reference/create-agent#param-system) can take a function receiving the current Network state as argument, enabling more flexibility in the Agent's behavior

  * Here, the `system` function is used to generate a prompt for the LLM based on the available Agents in the Network, enabling the LLM to plan the workflow to run

* The `code_assistant_agent` relies on two Tools to achieve its goal:
  * `read_file` to read the code file from disk and save it into the shared State
  * `generate_plan` to generate a plan of agents to run and save it into the shared State

The pattern of dynamic `system` prompt and tools are also used by the `summarization_agent` to generate a summary of the suggestions made by other agents.

**The Summarization Agent**

```typescript {3, 10}
const summarizationAgent = createAgent({
  name: "summarization_agent",
  system: ({ network }) => {
    const suggestions = network?.state.kv.get("suggestions") || [];
    return `Save a summary of the following suggestions:
    ${suggestions.join("\n")}`;
  },
  tools: [
    createTool({
      name: "save_summary",
      description:
        "Save a summary of the suggestions made by other agents into the state",
      parameters: z.object({
        summary: z.string(),
      }),
      handler: async (input, { network }) => {
        network?.state.kv.set("summary", input.summary);
        return "Saved!";
      },
    }),
  ],
});
```

<Note>
  The `summarization_agent` is a good example on how the State can be used to
  store intermediate results and pass them to the next Agent: - the
  `suggestions` are stored in the State by the `documentation_agent` and
  `analysis_agent` - the `summarization_agent` will read the `suggestions` from
  the State and generate a summary - the summary is then stored in the State as
  the `summary` key
</Note>

Our four Agents are now propely defined and connected to the Network's State.

Let's now configure our Network to run the Agents with a Router.

### Assembling the Network

An AgentKit [Network](/concepts/network) is defined by a set of Agents and an optional `defaultModel`:

```typescript {7-16}
import { createNetwork, anthropic } from "@inngest/agent-kit";

// Agent and Tools definitions...

const network = createNetwork({
  name: "code-assistant-v2",
  agents: [
    codeAssistantAgent,
    documentationAgent,
    analysisAgent,
    summarizationAgent,
  ],
  defaultModel: anthropic({
    model: "claude-3-5-sonnet-latest",
    max_tokens: 4096,
  }),
});
```

<Tip>
  The `defaultModel` will be applied to all Agents part of the Network.
  A model can also be set on an individual Agent by setting the `model` property.

  Learn more about the [Network Model configuration](/concepts/networks#model-configuration).
</Tip>

Our Code Assistant v2 is missing a final piece: the Router.
Without a Router, the Network will not know which Agent to run next.

**Implementing the Router**

As stated in the [workflow overview](#overview-of-the-agentic-workflow), our Code Assistant v2 is an agentic worflow composed of the following steps:

1. The `code_assistant_agent` will read the code file from disk and generate a plan of agents to run
2. Depending on the plan, the Network will run the next Agent in the plan (*ex: `analysis_agent` and `documentation_agent`*)
3. Finally, the `summarization_agent` will generate a summary of the suggestions made by other agents

AgentKit's Router enables us to implement such dynamic workflow with code by providing a `defaultRouter` function:

```typescript {9-24}
const network = createNetwork({
  name: "code-assistant-v2",
  agents: [
    codeAssistantAgent,
    documentationAgent,
    analysisAgent,
    summarizationAgent,
  ],
  router: ({ network }) => {
    if (!network?.state.kv.has("code") || !network?.state.kv.has("plan")) {
      return codeAssistantAgent;
    } else {
      const plan = (network?.state.kv.get("plan") || []) as string[];
      const nextAgent = plan.pop();
      if (nextAgent) {
        network?.state.kv.set("plan", plan);
        return network?.agents.get(nextAgent);
      } else if (!network?.state.kv.has("summary")) {
        return summarizationAgent;
      } else {
        return undefined;
      }
    }
  },
  defaultModel: anthropic({
    model: "claude-3-5-sonnet-latest",
    max_tokens: 4096,
  }),
});
```

<Note>
  **How does a Router work?**

  The Router is a function called by the Network when starting a new run and between each Agent call.

  The provided Router function (`defaultRouter`) receives a `network` argument granting access to the Network's state and Agents.

  Learn more about the [Router](/concepts/router).
</Note>

Let's have a closer look at the Router implementation:

```typescript
const router = ({ network }) => {
  // the first iteration of the network will have an empty state
  //  also, the first run of `code_assistant_agent` will store the `code`,
  //  requiring a second run to generate the plan
  if (!network?.state.kv.has("code") || !network?.state.kv.has("plan")) {
    return codeAssistantAgent;
  } else {
    // once the `plan` available in the state, we iterate over the agents to execute
    const plan = (network?.state.kv.get("plan") || []) as string[];
    const nextAgent = plan.pop();
    if (nextAgent) {
      network?.state.kv.set("plan", plan);
      return network?.agents.get(nextAgent);
      // we no agents are left to run, we generate a summary
    } else if (!network?.state.kv.has("summary")) {
      return summarizationAgent;
      // if no agent are left to run and a summary is available, we are done
    } else {
      return undefined;
    }
  }
};
```

Our Code Assistant v2 iteration is now complete. Let's run it!

## Running the Code Assistant v2

First, go to your Anthropic dashboard and create a new API key.

Then, run the following command to execute our Code Assistant:

<CodeGroup>
  ```bash npm
  ANTHROPIC_API_KEY=<your-api-key> npm run start
  ```

  ```bash pnpm
  ANTHROPIC_API_KEY=<your-api-key> pnpm run start
  ```

  ```bash yarn
  ANTHROPIC_API_KEY=<your-api-key> yarn run start
  ```
</CodeGroup>

The following output should be displayed in your terminal:

```txt
Analysis: The code analysis suggests several key areas for improvement:

1. Type Safety and Structure:
- Implement strict TypeScript configurations
- Add explicit return types and interfaces
- Break down complex functions
- Follow Single Responsibility Principle
- Implement proper error handling

2. Performance Optimization:
- Review and optimize critical operations
- Consider caching mechanisms
- Improve data processing efficiency

3. Documentation:
- Add comprehensive JSDoc comments
- Document complex logic and assumptions
- Create detailed README
- Include setup and usage instructions
- Add code examples
```

<Note>
  Updating the `files/example.ts` by applying the suggestions and running the Code Assistant again will yield a different planning with a different summary.

  Try it out!
</Note>

## What we've learned so far

Let's recap what we've learned so far:

* **Agentic workflows**, compared to RAG workflows, **are more flexible** and can be used to perform more complex tasks
* **Combining multiple Agents improves the accuracy** of the LLM reasoning and can save tokens
* **AgentKit enables to combine multiple Agents** into a [Network](/concepts/networks), connected by a common [State](/concepts/state)
* **AgentKit's Router enables to implement our workflow with code**, keeping control over our reasoning planning

## Next steps

This Code Assistant v2 shines by its analysis capabilities, but cannot be qualified as an AI Agent.

In the next version of our Code Assistant, we will transform it into a semi-autonomous AI Agent that can solve bugs and improve code of a small project.

<Card title="Code Assistant v3: Autonomous Code Assistant" href="/ai-agents-in-practice/ai-agents" icon="brain">
  The final version update of our Code Assistant will transform it into a
  semi-autonomous AI Agent.
</Card>


# Code Assistant v3: Autonomous Bug Solver
Source: https://agentkit.inngest.com/guided-tour/ai-agents

Build a custom Agent Router to autonomously solve bugs.

## Overview

Our [Code Assistant v2](/ai-agents-in-practice/agentic-workflows) introduced some limited reasoning capabilities through Tools and a Network of Agents.
This third version will transform our Code Assistant into a semi-autonomous AI Agent that can solve bugs and improve code.

Our AI Agent will operate over an Express API project containing bugs:

```txt
/examples/code-assistant-agent/project
├── package.json
├── tsconfig.json
├── src
│   ├── index.ts
│   ├── routes
│   │   ├── users.ts
│   │   └── posts.ts
│   ├── models
│   │   ├── user.ts
│   │   └── post.ts
│   └── db.ts
└── tests
    ├── users.test.ts
    └── posts.test.ts

```

Given a prompt such as:

```txt
Can you help me fix the following error?
1. TypeError: Cannot read properties of undefined (reading 'body')
   at app.post (/project/src/routes/users.ts:10:23)
```

Our Code Assistant v3 will autonomously navigate through the codebase and fix the bug by updating the impacted files.

This new version relies on previously covered concepts such as [Tools](/concepts/tools), [Agents](/concepts/agent), and [Networks](/concepts/network) but introduces
the creation of a custom [Router Agent](/concepts/routers#routing-agent-autonomous-routing) bringing routing autonomy to the AI Agent.

Let's learn these concepts in practice.

## Setup

Similarly to the [Code Assistant v2](/ai-agents-in-practice/agentic-workflows), perform the following steps to setup your project:

<AccordionGroup>
  <Accordion title="1. Initialize your project" defaultOpen="true">
    <CodeGroup>
      ```bash npm
      npm init
      ```

      ```bash pnpm
      pnpm init
      ```

      ```bash yarn
      yarn init
      ```
    </CodeGroup>
  </Accordion>

  <Accordion title="2. Install the required dependencies">
    <CodeGroup>
      ```bash npm
      npm install @inngest/agent-kit zod
      ```

      ```bash pnpm
      pnpm install @inngest/agent-kit zod
      ```

      ```bash yarn
      yarn add @inngest/agent-kit zod
      ```
    </CodeGroup>
  </Accordion>

  <Accordion title="3. Add TypeScript support">
    <CodeGroup>
      ```bash npm
      npm install -D tsx @types/node
      ```

      ```bash pnpm
      pnpm install -D tsx @types/node
      ```

      ```bash yarn
      yarn add -D tsx @types/node
      ```
    </CodeGroup>

    And add the following scripts to your `package.json`:

    ```json
    "scripts": {
        "start": "tsx ./index.ts"
    }
    ```
  </Accordion>
</AccordionGroup>

You are now set up, let's implement our autonomous Code Assistant.

## Implementing our Code Assistant v3

### Overview of the autonomous workflow

Our Code Assistant v3 introduces autonomy through a specialized Router Agent that orchestrates two task-specific Agents:

* `plannerAgent`: Analyzes code and plans fixes using code search capabilities
* `editorAgent`: Implements the planned fixes using file system operations

The Router Agent acts as the "brain" of our Code Assistant, deciding which Agent to use based on the current context and user request.

Let's implement each component of our autonomous workflow.

### Implementing the Tools

Our Code Assistant v3 needs to interact with the file system and search through code. Let's implement these capabilities as Tools:

```typescript {10, 12, 28}
import { createTool } from "@inngest/agent-kit";

const writeFile = createTool({
  name: "writeFile",
  description: "Write a file to the filesystem",
  parameters: z.object({
    path: z.string().describe("The path to the file to write"),
    content: z.string().describe("The content to write to the file"),
  }),
  handler: async ({ path, content }) => {
    try {
      let relativePath = path.startsWith("/") ? path.slice(1) : path;
      writeFileSync(relativePath, content);
      return "File written";
    } catch (err) {
      console.error(`Error writing file ${path}:`, err);
      throw new Error(`Failed to write file ${path}`);
    }
  },
});

const readFile = createTool({
  name: "readFile",
  description: "Read a file from the filesystem",
  parameters: z.object({
    path: z.string().describe("The path to the file to read"),
  }),
  handler: async ({ path }) => {
    try {
      let relativePath = path.startsWith("/") ? path.slice(1) : path;
      const content = readFileSync(relativePath, "utf-8");
      return content;
    } catch (err) {
      console.error(`Error reading file ${path}:`, err);
      throw new Error(`Failed to read file ${path}`);
    }
  },
});

const searchCode = createTool({
  name: "searchCode",
  description: "Search for a given pattern in a project files",
  parameters: z.object({
    query: z.string().describe("The query to search for"),
  }),
  handler: async ({ query }) => {
    const searchFiles = (dir: string, searchQuery: string): string[] => {
      const results: string[] = [];
      const walk = (currentPath: string) => {
        const files = readdirSync(currentPath);
        for (const file of files) {
          const filePath = join(currentPath, file);
          const stat = statSync(filePath);
          if (stat.isDirectory()) {
            walk(filePath);
          } else {
            try {
              const content = readFileSync(filePath, "utf-8");
              if (content.includes(searchQuery)) {
                results.push(filePath);
              }
            } catch (err) {
              console.error(`Error reading file ${filePath}:`, err);
            }
          }
        }
      };
      walk(dir);
      return results;
    };
    const matches = searchFiles(process.cwd(), query);
    return matches.length === 0
      ? "No matches found"
      : `Found matches in following files:\n${matches.join("\n")}`;
  },
});
```

<Note>
  Some notes on the highlighted lines:

  * As noted in the ["Building Effective Agents" article](https://www.anthropic.com/research/building-effective-agents) from Anthropic, Tools based on file system operations are most effective when provided with absolute paths.
  * Tools performing action such as `writeFile` should always return a value to inform the Agent that the action has been completed.
</Note>

These Tools provide our Agents with the following capabilities:

* `writeFile`: Write content to a file
* `readFile`: Read content from a file
* `searchCode`: Search for patterns in project files

Let's now create our task-specific Agents.

### Creating the Task-Specific Agents

Our Code Assistant v3 relies on two specialized Agents:

```typescript
import { createAgent } from "@inngest/agent-kit";

const plannerAgent = createAgent({
  name: "planner",
  system: "You are an expert in debugging TypeScript projects.",
  tools: [searchCode],
});

const editorAgent = createAgent({
  name: "editor",
  system: "You are an expert in fixing bugs in TypeScript projects.",
  tools: [writeFile, readFile],
});
```

Each Agent has a specific role:

* `plannerAgent` uses the `searchCode` Tool to analyze code and plan fixes
* `editorAgent` uses the `readFile` and `writeFile` Tools to implement fixes

Separating the Agents into two distinct roles will enable our AI Agent to better *"divide and conquer"* the problem to solve.

Let's now implement the Router Agent that will bring the reasoning capabilities to autonomously orchestrate these Agents.

### Implementing the Router Agent

The [Router Agent](/concepts/routers#routing-agent-autonomous-routing) is the "brain" of our Code Assistant, deciding which Agent to use based on the context.

The router developed in the [Code Assistant v2](/ai-agents-in-practice/agentic-workflows) was a function that decided which Agent to call next
based on the progress of the workflow. Such router made a Agent deterministic, but lacked the reasoning capabilities to autonomously orchestrate the Agents.

In this version, we will provide an Agent as a router, called a Router Agent.
By doing so, we can leverage the reasoning capabilities of the LLM to autonomously orchestrate the Agents around a given goal (here, fixing the bug).

Creating a Router Agent is done by using the [`createRoutingAgent`](/reference/network-router#createroutingagent) helper function:

```typescript {5, 38, 70}
import { createRoutingAgent } from "@inngest/agent-kit";

const router = createRoutingAgent({
  name: "Code Assistant routing agent",
  system: async ({ network }): Promise<string> => {
    if (!network) {
      throw new Error(
        "The routing agent can only be used within a network of agents"
      );
    }
    const agents = await network?.availableAgents();
    return `You are the orchestrator between a group of agents. Each agent is suited for a set of specific tasks, and has a name, instructions, and a set of tools.
      
      The following agents are available:
      <agents>
      ${agents
        .map((a) => {
          return `
        <agent>
          <name>${a.name}</name>
          <description>${a.description}</description>
          <tools>${JSON.stringify(Array.from(a.tools.values()))}</tools>
        </agent>`;
        })
        .join("\n")}
      </agents>
      
      Follow the set of instructions:
      
      <instructions>
      Think about the current history and status.
      If the user issue has been fixed, call select_agent with "finished"
      Otherwise, determine which agent to use to handle the user's request, based off of the current agents and their tools.
      
      Your aim is to thoroughly complete the request, thinking step by step, choosing the right agent based off of the context.
      </instructions>`;
  },
  tools: [
    createTool({
      name: "select_agent",
      description:
        "select an agent to handle the input, based off of the current conversation",
      parameters: z
        .object({
          name: z
            .string()
            .describe("The name of the agent that should handle the request"),
        })
        .strict(),
      handler: ({ name }, { network }) => {
        if (!network) {
          throw new Error(
            "The routing agent can only be used within a network of agents"
          );
        }
        if (name === "finished") {
          return undefined;
        }
        const agent = network.agents.get(name);
        if (agent === undefined) {
          throw new Error(
            `The routing agent requested an agent that doesn't exist: ${name}`
          );
        }
        return agent.name;
      },
    }),
  ],
  tool_choice: "select_agent",
  lifecycle: {
    onRoute: ({ result }) => {
      const tool = result.toolCalls[0];
      if (!tool) {
        return;
      }
      const agentName = (tool.content as any).data || (tool.content as string);
      if (agentName === "finished") {
        return;
      } else {
        return [agentName];
      }
    },
  },
});
```

Looking at the highlighted lines, we can see that a Router Agent mixes features from regular Agents and a function Router:

1. A Router Agent is a regular Agent with a `system` function that returns a prompt
2. A Router Agent can use [Tools](/concepts/tools) to interact with the environment
3. Finally, a Router Agent can also define lifecycle callbacks, [like Agents do](/concepts/agents#lifecycle-hooks)

Let's now dissect how this Router Agent works:

1. The `system` function is used to define the prompt dynamically based on the Agents available in the Network
   * You will notice that the prompt explicitly ask to call a "finished" tool when the user issue has been fixed
2. The `select_agent` Tool is used to validate that the Agent selected is available in the Network
   * The tool ensures that the "finished" edge case is handled
3. The `onRoute` lifecycle callback is used to determine which Agent to call next
   * This callback stops the conversation when the user issue has been fixed (when the "finished" Agent is called)

This is it! Using this prompt, our Router Agent will orchestrate the Agents until the given bug is fixed.

### Assembling the Network

Finally, assemble the Network of Agents and Router Agent:

```typescript
const network = createNetwork({
  name: "code-assistant-v3",
  agents: [plannerAgent, editorAgent],
  defaultModel: anthropic({
    model: "claude-3-5-sonnet-latest",
    max_tokens: 4096,
  }),
  router: router,
});
```

Our Code Assistant v3 is now complete and ready to be used!

## Running our Code Assistant v3

First, go to your Anthropic dashboard and create a new API key.

Then, run the following command to start the server:

<CodeGroup>
  ```bash npm
  ANTHROPIC_API_KEY=<your-api-key> npm run start
  ```

  ```bash pnpm
  ANTHROPIC_API_KEY=<your-api-key> pnpm run start
  ```

  ```bash yarn
  ANTHROPIC_API_KEY=<your-api-key> yarn run start
  ```
</CodeGroup>

Your Code Assistant is now running at `http://localhost:3010` and ready to help fix bugs in your TypeScript projects!

## What we've learned so far

Let's recap what we've learned so far:

* **Autonomous AI Agents** can be built by using [**Router Agents**](/concepts/routers#routing-agent-autonomous-routing), which act as the "brain" of an autonomous system by orchestrating other Agents
* **Tools** provide Agents with capabilities to interact with their environment


# Code Assistant v1: Explaining a given code file
Source: https://agentkit.inngest.com/guided-tour/ai-workflows

Leveraging AgentKit's Agent concept to power a RAG workflow.

## Overview

As discussed in the [introduction](/ai-agents-in-practice/overview), developing AI applications is a pragmatic approach requiring
to start simple and iterate towards complexity.

Following this approach, this first version of our Code Assistant will be able to explain a given code file:

```typescript
const filePath = join(process.cwd(), `files/example.ts`);
const code = readFileSync(filePath, "utf-8");

const { lastMessage } = await codeAssistant.run(`What the following code does?

${code}
`);

console.log(lastMessage({ type: "text" }).content);
// This file (example.ts) is a TypeScript module that provides a collection of type-safe sorting helper functions. It contains five main sorting utility functions:

// 1. `sortNumbers(numbers: number[], descending = false)`
//    - Sorts an array of numbers in ascending (default) or descending order
//    - Takes an array of numbers and an optional boolean to determine sort direction

// 2. `sortStrings(strings: string[], options)`
//    - Sorts strings alphabetically with customizable options
//    - Options include:
//      - caseSensitive (default: false)
//      - descending (default: false)

// ...
```

To implement this capability, we will build a AI workflow leveraging a first important concept of AgentKit:

* [Agents](/concepts/agents): Agents act as a wrapper around the LLM (ex: Anthropic), providing a structured way to interact with it.

Let's start our Code Assistant by installing the required dependencies:

## Setup

Follow the below steps to setup your project:

<AccordionGroup>
  <Accordion title="1. Initialize your project" defaultOpen="true">
    <CodeGroup>
      ```bash npm
      npm init
      ```

      ```bash pnpm
      pnpm init
      ```

      ```bash yarn
      yarn init
      ```
    </CodeGroup>
  </Accordion>

  <Accordion title="2. Install the required dependencies">
    <CodeGroup>
      ```bash npm
      npm install @inngest/agent-kit
      ```

      ```bash pnpm
      pnpm install @inngest/agent-kit
      ```

      ```bash yarn
      yarn add @inngest/agent-kit
      ```
    </CodeGroup>
  </Accordion>

  <Accordion title="3. Add TypeScript support">
    <CodeGroup>
      ```bash npm
      npm install -D tsx @types/node
      ```

      ```bash pnpm
      pnpm install -D tsx @types/node
      ```

      ```bash yarn
      yarn add -D tsx @types/node
      ```

      And add the following scripts to your `package.json`:

      ```json
      "scripts": {
          "start": "tsx ./index.ts"
      }
      ```
    </CodeGroup>
  </Accordion>

  <Accordion title="4. Download the example code file">
    <CodeGroup>
      ```bash
      wget https://raw.githubusercontent.com/inngest/agent-kit/main/examples/code-assistant-rag/files/example.ts
      ```
    </CodeGroup>
  </Accordion>
</AccordionGroup>

You are now set up, let's implement the first version of our Code Assistant.

## Implementing our Code Assistant v1

Our first version of our Code Assistant takes the shape of a RAG workflow.
A RAG workflow is a specific type of AI workflow that genrally consist of two steps: retrieval (fetching relevant information) and generation (creating a response with a LLM).

Our Code Assistant will have following two steps:

* **A retrieval step** reads the content of a local file specified by the user.
* **A generation step** uses Anthropic to analyze the code and provide a detailed explanation of what it does.

Let's start by implementing the retrieval step.

### The retrieval step: loading the code file

We earlier downloaded the `example.ts` file locally, let's load it in our code by creating a `index.ts` file:

```typescript {5-7}
import { readFileSync } from "fs";
import { join } from "path";

async function main() {
  // First step: Retrieval
  const filePath = join(process.cwd(), `files/example.ts`);
  const code = readFileSync(filePath, "utf-8");
}

main();
```

Our example code is now ready to be analyzed. Let's now implement the generation step.

### The generation step using AgentKit's Agent

As covered in the introduction, [AgentKit's `createAgent()`](/reference/create-agent) is a wrapper around the LLM, providing a structured way to interact with it with 3 main properties:

* `name`: A unique identifier for the agent.
* `system`: A description of the agent's purpose.
* `model`: The LLM to use.

Let's add configure our Agent with Anthropic's `claude-3-5-sonnet-latest` model by updating our `index.ts` file:

```typescript {5-13}
import { readFileSync } from "fs";
import { join } from "path";
import { anthropic, createAgent } from "@inngest/agent-kit";

const codeAssistant = createAgent({
  name: "code_assistant",
  system:
    "An AI assistant that helps answer questions about code by reading and analyzing files",
  model: anthropic({
    model: "claude-3-5-sonnet-latest",
    max_tokens: 4096,
  }),
});


async function main() {
  // First step: Retrieval
  const filePath = join(process.cwd(), `files/example.ts`);
  const code = readFileSync(filePath, "utf-8");
}

main();
```

Let's now update our `main()` function to use our `codeAssistant` Agent in the generation step:

```typescript {21-29}
/* eslint-disable */
import { readFileSync } from "fs";
import { join } from "path";
import { anthropic, createAgent } from "@inngest/agent-kit";

// Create the code assistant agent
const codeAssistant = createAgent({
  name: "code_assistant",
  system:
    "An AI assistant that helps answer questions about code by reading and analyzing files",
  model: anthropic({
    model: "claude-3-5-sonnet-latest",
    max_tokens: 4096,
  }),
});

async function main() {
  // First step: Retrieval
  const filePath = join(process.cwd(), `files/example.ts`);
  const code = readFileSync(filePath, "utf-8");
  // Second step: Generation
  const { output } = await codeAssistant.run(`What the following code does?

  ${code}
  `);
  const lastMessage = output[output.length - 1];
  const content =
    lastMessage?.type === "text" ? (lastMessage?.content as string) : "";
  console.log(content);
}

main();
```

Let's review the above code:

1. We load the `example.ts` file in memory.
2. We invoke our Code Assistant using the `codeAssistant.run()` method.
3. We retrieve the last message from the `output` array.
4. We log the content of the last message to the console.

Let's now look at our assistant explanation.

## Running our Code Assistant v1

First, go to your Anthropic dashboard and create a new API key.

Then, run the following command to execute our Code Assistant:

<CodeGroup>
  ```bash npm
  ANTHROPIC_API_KEY=<your-api-key> npm run start
  ```

  ```bash pnpm
  ANTHROPIC_API_KEY=<your-api-key> pnpm run start
  ```

  ```bash yarn
  ANTHROPIC_API_KEY=<your-api-key> yarn run start
  ```
</CodeGroup>

The following output should be displayed in your terminal:

```
This code is a collection of type-safe sorting utility functions written in TypeScript. Here's a breakdown of each function:

1. `sortNumbers(numbers: number[], descending = false)`
- Sorts an array of numbers in ascending (default) or descending order
- Returns a new sorted array without modifying the original

2. `sortStrings(strings: string[], options)`
- Sorts an array of strings alphabetically
- Accepts options for case sensitivity and sort direction
- Default behavior is case-insensitive ascending order
- Returns a new sorted array

3. `sortByKey<T>(items: T[], key: keyof T, descending = false)`
- Sorts an array of objects by a specific key
- Handles both number and string values
- Generic type T ensures type safety
- Returns a new sorted array

4. `sortByMultipleKeys<T>(items: T[], sortKeys: Array<...>)`
- Sorts an array of objects by multiple keys in order
- Each key can have its own sort configuration (descending, case sensitivity)
- Continues to next key if values are equal
- Returns a new sorted array

...
```

Congratulations! You've just built your first AI workflow using AgentKit.

## What we've learned so far

Let's recap what we've learned so far:

* **A RAG workflow** is a specific type of AI workflow that generally consist of two steps: retrieval (fetching relevant information) and generation (creating a response with a LLM).
  * *Note that most RAG workflows in production consist of more than two steps and combine multiple sources of information and generation steps. You can see an example in [this blog post](https://www.inngest.com/blog/next-generation-ai-workflows?ref=agentkit-docs).*
* **AgentKit's `createAgent()`** is a wrapper around the LLM, providing a structured way to interact with a LLM model.
  * *The use of a single Agent is often sufficient to power chatbots or extract structured data from a given text.*

## Next steps

Our Code Assistant v1 is a static AI workflow that only works with the `example.ts` file.

In the next version of our Code Assistant, we will make it dynamic by allowing the user to specify the file to analyze and also enable our Agent to perform more complete analysis.

<Card title="Code Assistant v2: Complex code analysis" href="/ai-agents-in-practice/agentic-workflows" icon="bolt">
  Our next Code Assistant version will rely on Agentic workflows to perform more complex code analysis.
</Card>


# The three levels of AI apps
Source: https://agentkit.inngest.com/guided-tour/overview

A comprehensive guide to building AI Agents with AgentKit

AI Agents can be a complex topic to understand and differentiate from RAG, AI workflows, Agentic workflows, and more.
This guide will provide a definition of AI Agents with practical examples inspired by the [Building effective agents](https://www.anthropic.com/research/building-effective-agents) manifesto from Anthropic.

Developing AI applications leverages multiple patterns from AI workflows with static steps to fully autonomous AI Agents, each fitting specific use cases.
The best way to start is to begin simple and iterate towards complexity.

This guide features a Code Assistant that will will progressively evolve from a static AI workflow to an autonomous AI Agent.

Below are the different versions of our Code Assistant, each progressively adding more autonomy and complexity:

<Card title={<div className="flex items-center gap-2"><span className="border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">v1</span> {"Explaining a given code file"}</div>} href="/ai-agents-in-practice/ai-workflows">
  The first version starts as a AI workflow using a tool to provide a file as context to the LLM (RAG).
</Card>

<Card title={<div className="flex items-center gap-2"><span className="border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">v2</span> {"Performing complex code analysis"}</div>} href="/ai-agents-in-practice/agentic-workflows">
  Then, we will add Agentic capabilities to our assistant to enable it more complex analysis.
</Card>

<Card title={<div className="flex items-center gap-2"><span className="border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">v3</span> {"Autonomously reviewing a pull request"}</div>} href="/ai-agents-in-practice/ai-agents">
  Finally, we will add more autonomy to our assistant, transforming it into a semi-autonomous AI Agent.
</Card>

<Card title={<div className="flex items-center gap-2"><span className="border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">New</span> {"Pushing our Code Assistant to production"}</div>} href="/concepts/deployment">
  Discover the best practices to deploy your AI Agents to production.
</Card>

Depending on your experience developing AI applications, you can choose to start directly with the second part covering Agentic workflows.

Happy coding!


# Using AgentKit with Browserbase
Source: https://agentkit.inngest.com/integrations/browserbase

Develop AI Agents that can browse the web

[Browserbase](https://www.browserbase.com/) provides managed [headless browsers](https://docs.browserbase.com/introduction/what-is-headless-browser) to
enable Agents to browse the web autonomously.

There are two ways to use Browserbase with AgentKit:

* **Create your own Browserbase tools**: useful if you want to build simple actions on webpages with manual browser control.
* **Use Browserbase's [Stagehand](https://www.stagehand.dev/) library as tools**: a better approach for autonomous browsing and resilient scraping.

## Building AgentKit tools using Browserbase

Creating AgentKit [tools](/concepts/tools) using the Browserbase TypeScript SDK is straightforward.

<Steps>
  <Step title="Install AgentKit">
    Within an existing project, install AgentKit, Browserbase and Playwright core:

    <CodeGroup>
      ```shell npm
      npm install @inngest/agent-kit @browserbasehq/sdk playwright-core
      ```

      ```shell pnpm
      pnpm install @inngest/agent-kit @browserbasehq/sdk playwright-core
      ```

      ```shell yarn
      yarn add @inngest/agent-kit @browserbasehq/sdk playwright-core
      ```
    </CodeGroup>

    <Accordion title="Don't have an existing project?">
      To create a new project, create a new directory then initialize using your package manager:

      <CodeGroup>
        ```shell npm
        mkdir my-agent-kit-project && npm init
        ```

        ```shell pnpm
        mkdir my-agent-kit-project && pnpm init
        ```

        ```shell yarn
        mkdir my-agent-kit-project && yarn init
        ```
      </CodeGroup>
    </Accordion>
  </Step>

  <Step title="2. Setup an AgentKit Newtork with an Agent">
    Create a Agent and its associated Network, for example a Reddit Search Agent:

    ```typescript
    import {
      anthropic,
      createAgent,
      createNetwork,
    } from "@inngest/agent-kit";

    const searchAgent = createAgent({
      name: "reddit_searcher",
      description: "An agent that searches Reddit for relevant information",
      system:
      "You are a helpful assistant that searches Reddit for relevant information.",
    });

    // Create the network
    const redditSearchNetwork = createNetwork({
      name: "reddit_search_network",
      description: "A network that searches Reddit using Browserbase",
      agents: [searchAgent],
      maxIter: 2,
      defaultModel: anthropic({
      model: "claude-3-5-sonnet-latest",
      max_tokens: 4096,
    });

    ```
  </Step>

  <Step title="Create a Browserbase tool">
    Let's configure the Browserbase SDK and create a tool that can search Reddit:

    ```typescript {5, 8-9, 11-13}
    import {
      anthropic,
      createAgent,
      createNetwork,
      createTool,
    } from "@inngest/agent-kit";
    import { z } from "zod";
    import { chromium } from "playwright-core";
    import Browserbase from "@browserbasehq/sdk";

    const bb = new Browserbase({
      apiKey: process.env.BROWSERBASE_API_KEY as string,
    });

    // Create a tool to search Reddit using Browserbase
    const searchReddit = createTool({
      name: "search_reddit",
      description: "Search Reddit posts and comments",
      parameters: z.object({
        query: z.string().describe("The search query for Reddit"),
      }),
      handler: async ({ query }, { step }) => {
        return await step?.run("search-on-reddit", async () => {
          // Create a new session
          const session = await bb.sessions.create({
            projectId: process.env.BROWSERBASE_PROJECT_ID as string,
          });

          // Connect to the session
          const browser = await chromium.connectOverCDP(session.connectUrl);
          try {
            const page = await browser.newPage();

            // Construct the search URL
            const searchUrl = `https://search-new.pullpush.io/?type=submission&q=${query}`;

            console.log(searchUrl);

            await page.goto(searchUrl);

            // Wait for results to load
            await page.waitForSelector("div.results", { timeout: 10000 });

            // Extract search results
            const results = await page.evaluate(() => {
              const posts = document.querySelectorAll("div.results div:has(h1)");
              return Array.from(posts).map((post) => ({
                title: post.querySelector("h1")?.textContent?.trim(),
                content: post.querySelector("div")?.textContent?.trim(),
              }));
            });

            console.log("results", JSON.stringify(results, null, 2));

            return results.slice(0, 5); // Return top 5 results
          } finally {
            await browser.close();
          }
        });
      },
    });
    ```

    <Info>
      Configure your `BROWSERBASE_API_KEY` and `BROWSERBASE_PROJECT_ID` in the
      `.env` file. You can find your API key and project ID from the [Browserbase
      dashboard](https://docs.browserbase.com/introduction/getting-started#creating-your-account).
    </Info>

    <Tip>
      We recommend building tools using Browserbase using Inngest's `step.run()` function. This ensures that the tool will only run once across multiple runs.

      More information about using `step.run()` can be found in the [Multi steps tools](/advanced-patterns/multi-steps-tools) page.
    </Tip>
  </Step>
</Steps>

### Example: Reddit Search Agent using Browserbase

You will find a complete example of a Reddit search agent using Browserbase in the Reddit Search Agent using Browserbase example:

<Card title="Reddit Search Agent using Browserbase" href="https://github.com/inngest/agent-kit/tree/main/examples/reddit-search-browserbase-tools#readme" icon="github">
  This examples shows how to build tools using Browserbase to power a Reddit search agent.

  <br />

  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Agents</span>
  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Tools</span>
  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Network</span>
  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Integrations</span>
</Card>

## Enable autonomous browsing with Stagehand

Building AgentKit tools using [Stagehand](https://www.stagehand.dev/) gives more autonomy to your agents.

Stagehand comes with 4 primary API that can be directly used as tools:

* `goto()`: navigate to a specific URL
* `observe()`: observe the current page
* `extract()`: extract data from the current page
* `act()`: take action on the current page

These methods can be easily directly be used as tools in AgentKit, enabling agents to browse the web autonomously.

Below is an example of a simple search agent that uses Stagehand to search the web:

```ts {22, 46-49, 66, 83}
import { createAgent, createTool } from "@inngest/agent-kit";
import { z } from "zod";
import { getStagehand, stringToZodSchema } from "./utils.js";

const webSearchAgent = createAgent({
  name: "web_search_agent",
  description: "I am a web search agent.",
  system: `You are a web search agent.
  `,
  tools: [
    createTool({
      name: "navigate",
      description: "Navigate to a given URL",
      parameters: z.object({
        url: z.string().describe("the URL to navigate to"),
      }),
      handler: async ({ url }, { step, network }) => {
        return await step?.run("navigate", async () => {
          const stagehand = await getStagehand(
            network?.state.kv.get("browserbaseSessionID")!
          );
          await stagehand.page.goto(url);
          return `Navigated to ${url}.`;
        });
      },
    }),
    createTool({
      name: "extract",
      description: "Extract data from the page",
      parameters: z.object({
        instruction: z
          .string()
          .describe("Instructions for what data to extract from the page"),
        schema: z
          .string()
          .describe(
            "A string representing the properties and types of data to extract, for example: '{ name: string, age: number }'"
          ),
      }),
      handler: async ({ instruction, schema }, { step, network }) => {
        return await step?.run("extract", async () => {
          const stagehand = await getStagehand(
            network?.state.kv.get("browserbaseSessionID")!
          );
          const zodSchema = stringToZodSchema(schema);
          return await stagehand.page.extract({
            instruction,
            schema: zodSchema,
          });
        });
      },
    }),
    createTool({
      name: "act",
      description: "Perform an action on the page",
      parameters: z.object({
        action: z
          .string()
          .describe("The action to perform (e.g. 'click the login button')"),
      }),
      handler: async ({ action }, { step, network }) => {
        return await step?.run("act", async () => {
          const stagehand = await getStagehand(
            network?.state.kv.get("browserbaseSessionID")!
          );
          return await stagehand.page.act({ action });
        });
      },
    }),
    createTool({
      name: "observe",
      description: "Observe the page",
      parameters: z.object({
        instruction: z
          .string()
          .describe("Specific instruction for what to observe on the page"),
      }),
      handler: async ({ instruction }, { step, network }) => {
        return await step?.run("observe", async () => {
          const stagehand = await getStagehand(
            network?.state.kv.get("browserbaseSessionID")!
          );
          return await stagehand.page.observe({ instruction });
        });
      },
    }),
  ],
});
```

<Info>
  These 4 AgentKit tools using Stagehand enables the Web Search Agent to browse the web autonomously.

  The `getStagehand()` helper function is used to retrieve the persisted instance created for the network execution (*see full code below*).
</Info>

You will find the complete example on GitHub:

<Card title="Simple Search Agent using Stagehand" href="https://github.com/inngest/agent-kit/tree/main/examples/simple-search-stagehand/#readme" icon="github">
  This examples shows how to build tools using Stagehand to power a simple search agent.

  <br />

  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Agents</span>
  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Tools</span>
  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Network</span>
  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Integrations</span>
</Card>


# Using AgentKit with E2B
Source: https://agentkit.inngest.com/integrations/e2b

Develop Coding Agents using E2B Sandboxes as tools

[E2B](https://e2b.dev) is an open-source runtime for executing AI-generated code in secure cloud sandboxes. Made for agentic & AI use cases.

E2B is a perfect fit to build Coding Agents that can write code, fix bugs, and more.

## Setup

<Steps>
  <Step title="Install AgentKit and E2B">
    Within an existing project, Install AgentKit and E2B from npm:

    <CodeGroup>
      ```shell npm
      npm install @inngest/agent-kit @e2b/code-interpreter
      ```

      ```shell pnpm
      pnpm install @inngest/agent-kit @e2b/code-interpreter
      ```

      ```shell yarn
      yarn add @inngest/agent-kit @e2b/code-interpreter
      ```
    </CodeGroup>

    <br />

    <Accordion title="Don't have an existing project?">
      To create a new project, create a new directory then initialize using your package manager:

      <CodeGroup>
        ```shell npm
        mkdir my-agent-kit-project && npm init
        ```

        ```shell pnpm
        mkdir my-agent-kit-project && pnpm init
        ```

        ```shell yarn
        mkdir my-agent-kit-project && yarn init
        ```
      </CodeGroup>
    </Accordion>
  </Step>

  <Step title="Setup your Coding Agent">
    Create a Agent and its associated Network:

    ```typescript
    import {
      createAgent,
      createNetwork,
      anthropic
    } from "@inngest/agent-kit";

    const agent = createAgent({
      name: "Coding Agent",
      description: "An expert coding agent",
      system: `You are a coding agent help the user to achieve the described task.

      Once the task completed, you should return the following information:
      <task_summary>
      </task_summary>

      Think step-by-step before you start the task.
      `,
      model: anthropic({
        model: "claude-3-5-sonnet-latest",
        max_tokens: 4096,
      }),
    });

    const network = createNetwork({
      name: "Coding Network",
      agents: [agent],
      defaultModel: anthropic({
        model: "claude-3-5-sonnet-20240620",
        maxTokens: 1000,
      })
    });

    ```
  </Step>

  <Step title="Create the E2B Tools">
    To operate, our Coding Agent will need to create files and run commands.

    Below is an example of how to create the `createOrUpdateFiles` and `terminal` E2B tools:

    ```typescript {5, 23-79}
    import {
      createAgent,
      createNetwork,
      anthropic,
      createTool
    } from "@inngest/agent-kit";

    const agent = createAgent({
      name: "Coding Agent",
      description: "An expert coding agent",
      system: `You are a coding agent help the user to achieve the described task.

      Once the task completed, you should return the following information:
      <task_summary>
      </task_summary>

      Think step-by-step before you start the task.
      `,
      model: anthropic({
        model: "claude-3-5-sonnet-latest",
        max_tokens: 4096,
      }),
      tools: [
        // terminal use
        createTool({
          name: "terminal",
          description: "Use the terminal to run commands",
          parameters: z.object({
            command: z.string(),
          }),
          handler: async ({ command }, { network }) => {
            const buffers = { stdout: "", stderr: "" };

            try {
              const sandbox = await getSandbox(network);
              const result = await sandbox.commands.run(command, {
                onStdout: (data: string) => {
                  buffers.stdout += data;
                },
                onStderr: (data: string) => {
                  buffers.stderr += data;
                },
              });
              return result.stdout;
            } catch (e) {
              console.error(
                `Command failed: ${e} \nstdout: ${buffers.stdout}\nstderr: ${buffers.stderr}`
              );
              return `Command failed: ${e} \nstdout: ${buffers.stdout}\nstderr: ${buffers.stderr}`;
            }
          },
        }),
        // create or update file
        createTool({
          name: "createOrUpdateFiles",
          description: "Create or update files in the sandbox",
          parameters: z.object({
            files: z.array(
              z.object({
                path: z.string(),
                content: z.string(),
              })
            ),
          }),
          handler: async ({ files }, { network }) => {
            try {
              const sandbox = await getSandbox(network);
              for (const file of files) {
                await sandbox.files.write(file.path, file.content);
              }
              return `Files created or updated: ${files
                .map((f) => f.path)
                .join(", ")}`;
            } catch (e) {
              return "Error: " + e;
            }
          },
        }),
      ]
    });

    const network = createNetwork({
      name: "Coding Network",
      agents: [agent],
      defaultModel: anthropic({
        model: "claude-3-5-sonnet-20240620",
        maxTokens: 1000,
      })
    });

    ```

    You will find the complete example in the [E2B Coding Agent example](https://github.com/inngest/agent-kit/tree/main/examples/e2b-coding-agent#readme).

    <Tip>
      **Designing useful tools**

      As covered in Anthropic's ["Tips for Building AI Agents"](https://www.youtube.com/watch?v=LP5OCa20Zpg),
      the best Agents Tools are the ones that you will need to accomplish the task by yourself.

      Do not map tools directly to the underlying API, but rather design tools that are useful for the Agent to accomplish the task.
    </Tip>
  </Step>
</Steps>

## Examples

<CardGroup cols={2}>
  <Card title="Replicate Cursor's Agent mode" href="https://github.com/inngest/agent-kit/tree/main/examples/e2b-coding-agent#readme" icon="github">
    This examples shows how to use E2B sandboxes to build a coding agent that can write code and run commands to generate complete project, complete refactoring and fix bugs.

    <br />

    <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Agents</span>
    <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Tools</span>
    <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Network</span>
    <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Integrations</span>

    <br />

    <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Code-based Router</span>
  </Card>

  <Card title="AI-powered CSV contacts importer" href="https://github.com/inngest/agent-kit/tree/main/examples/e2b-csv-contacts-importer#readme" icon="github">
    Let's reinvent the CSV upload UX with an AgentKit network leveraging E2B sandboxes.

    <br />

    <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Agents</span>
    <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Tools</span>
    <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Network</span>
    <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Integrations</span>

    <br />

    <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">Code-based Router</span>
  </Card>
</CardGroup>


# Smithery - MCP Registry
Source: https://agentkit.inngest.com/integrations/smithery

Provide your Agents with hundred of prebuilt tools to interact with

[Smithery](https://smithery.ai/) is an MCP ([Model Context Protocol](https://modelcontextprotocol.io/introduction)) servers registry, listing more than 2,000 MCP servers across multiple use cases:

* Code related tasks (ex: GitHub, [E2B](/integrations/e2b))
* Web Search Integration (ex: Brave, [Browserbase](/integrations/browserbase))
* Database Integration (ex: Neon, Supabase)
* Financial Market Data
* Data & App Analysis
* And more...

## Adding a Smithery MCP Server to your Agent

<Steps>
  <Step title="Install AgentKit">
    Within an existing project, install AgentKit along with the Smithery SDK:

    <CodeGroup>
      ```shell npm
      npm install @inngest/agent-kit @smithery/sdk
      ```

      ```shell pnpm
      pnpm install @inngest/agent-kit @smithery/sdk
      ```

      ```shell yarn
      yarn add @inngest/agent-kit @smithery/sdk
      ```
    </CodeGroup>

    <Accordion title="Don't have an existing project?">
      To create a new project, create a new directory then initialize using your package manager:

      <CodeGroup>
        ```shell npm
        mkdir my-agent-kit-project && npm init
        ```

        ```shell pnpm
        mkdir my-agent-kit-project && pnpm init
        ```

        ```shell yarn
        mkdir my-agent-kit-project && yarn init
        ```
      </CodeGroup>
    </Accordion>
  </Step>

  <Step title="2. Setup an AgentKit Newtork with an Agent">
    Create an Agent and its associated Network, for example a Neon Assistant Agent:

    ```typescript
    import { z } from "zod";
    import {
      anthropic,
      createAgent,
      createNetwork,
      createTool,
    } from "@inngest/agent-kit";

    const neonAgent = createAgent({
      name: "neon-agent",
      system: `You are a helpful assistant that help manage a Neon account.
      IMPORTANT: Call the 'done' tool when the question is answered.
      `,
      tools: [
        createTool({
          name: "done",
          description: "Call this tool when you are finished with the task.",
          parameters: z.object({
            answer: z.string().describe("Answer to the user's question."),
          }),
          handler: async ({ answer }, { network }) => {
            network?.state.kv.set("answer", answer);
          },
        }),
      ],
    });

    const neonAgentNetwork = createNetwork({
      name: "neon-agent",
      agents: [neonAgent],
      defaultModel: anthropic({
        model: "claude-3-5-sonnet-20240620",
        defaultParameters: {
          max_tokens: 1000,
        },
      }),
      router: ({ network }) => {
        if (!network?.state.kv.get("answer")) {
          return neonAgent;
        }
        return;
      },
    });
    ```
  </Step>

  <Step title="Add the Neon MCP Smithery Server to your Agent">
    Add the [Neon MCP Smithery Server](https://smithery.ai/server/neon/) to your Agent by using `createSmitheryUrl()` from the `@smithery/sdk/config.js` module
    and providing it to the Agent via the `mcpServers` option:

    ```typescript {7, 10-12, 31-39}
    import {
      anthropic,
      createAgent,
      createNetwork,
      createTool,
    } from "@inngest/agent-kit";
    import { createSmitheryUrl } from "@smithery/sdk/config.js";
    import { z } from "zod";

    const smitheryUrl = createSmitheryUrl("https://server.smithery.ai/neon/ws", {
      neonApiKey: process.env.NEON_API_KEY,
    });

    const neonAgent = createAgent({
      name: "neon-agent",
      system: `You are a helpful assistant that help manage a Neon account.
      IMPORTANT: Call the 'done' tool when the question is answered.
      `,
      tools: [
        createTool({
          name: "done",
          description: "Call this tool when you are finished with the task.",
          parameters: z.object({
            answer: z.string().describe("Answer to the user's question."),
          }),
          handler: async ({ answer }, { network }) => {
            network?.state.kv.set("answer", answer);
          },
        }),
      ],
      mcpServers: [
        {
          name: "neon",
          transport: {
            type: "ws",
            url: smitheryUrl.toString(),
          },
        },
      ],
    });

    const neonAgentNetwork = createNetwork({
      name: "neon-agent",
      agents: [neonAgent],
      defaultModel: anthropic({
        model: "claude-3-5-sonnet-20240620",
        defaultParameters: {
          max_tokens: 1000,
        },
      }),
      router: ({ network }) => {
        if (!network?.state.kv.get("answer")) {
          return neonAgent;
        }
        return;
      },
    });
    ```

    <Warning>
      Integrating Smithery with AgentKit requires using the `createSmitheryUrl()` function to create a valid URL for the MCP server.

      Most Smithery servers instruct to use the `createTransport()` function which is not supported by AgentKit.
      To use the `createSmitheryUrl()` function, simply append `/ws` to the end of the Smithery server URL provided by Smithery.
    </Warning>
  </Step>
</Steps>

You will find the complete example on GitHub:

<Card title="Neon Assistant Agent (using MCP)" href="https://github.com/inngest/agent-kit/tree/main/examples/mcp-neon-agent/#readme" icon="github">
  This examples shows how to use the [Neon MCP Smithery Server](https://smithery.ai/server/neon/) to build a Neon Assistant Agent that can help you manage your Neon databases.

  {" "}

  <br />

  {" "}

  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">
    Agents
  </span>

  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">
    Tools
  </span>

  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">
    Network
  </span>

  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">
    Integrations
  </span>

  <br />

  <span className="mr-2 border-primary dark:border-primary-light bg-primary/10 text-primary text-xs dark:text-primary-light dark:bg-primary-light/10 rounded-xl px-2 py-1">
    Code-based Router
  </span>
</Card>


# AgentKit
Source: https://agentkit.inngest.com/overview

A TypeScript library to create and orchestrate AI Agents.

AgentKit is a framework to build AI Agents, from single model inference calls to multi-agent systems that use tools. Designed with orchestration at its core, AgentKit enables developers to build, test, and deploy reliable AI applications at scale.

With AgentKit, you get:

✨ **Simple and composable primitives** to build from simple Support Agents to semi-autonomous Coding Agents.

🧠 **Support for [OpenAI, Anthropic, Gemini](/concepts/models)** and all OpenAI API compatible models.

🛠️ **Powerful tools building API** with support for [MCP as tools](/advanced-patterns/mcp).

🔌 **Integrates** with your favorite AI libraries and products (ex: [E2B](/integrations/e2b), [Browserbase](/integrations/browserbase), [Smithery](/integrations/smithery)).

⚡ **Stream live updates** to your UI with [UI Streaming](/advanced-patterns/ui-streaming).

📊 **[Local Live traces](/getting-started/local-development) and input/output logs** when combined with the Inngest Dev Server.

<br />

New to AI Agents? Follow our [Guided Tour](/guided-tour/overview) to learn how to build your first AgentKit application.

All the above sounds familiar? Check our **[Getting started section](#getting-started)** or the **["How AgentKit works" section](#how-agentkit-works)** to learn more about AgentKit's architecture.

## Getting started

<CardGroup>
  <Card title="Quick start" href="/getting-started/quick-start">
    Jump into the action by building your first AgentKit application.
  </Card>

  <Card title="Examples" href="/examples/overview">
    Looking for inspiration? Check out our examples to see how AgentKit can be
    used.
  </Card>

  <Card title="Concepts" href="/concepts/agents">
    Learn the core concepts of AgentKit.
  </Card>

  <Card title="SDK Reference" href="/reference/introduction">
    Ready to dive into the code? Browse the SDK reference to learn more about
    AgentKit's primitives.
  </Card>
</CardGroup>

## How AgentKit works

<div className="flex gap-4">
  <div className="flex-1 py-8 mr-5">
    AgentKit enables developers to compose simple single-agent systems or entire
    *systems of agents* in which multiple agents can work together.
    **[Agents](/concepts/agents)** are combined into
    **[Networks](concepts/networks)** which include a
    **[Router](concepts/routers)** to determine which Agent should be called.
    Their system's memory is recorded as Network **[State](concepts/state)** which
    can be used by the Router, Agents or **[Tools](concepts/tools)** to
    collaborate on tasks.
  </div>

  <div className="flex-1">
    <Frame>
      ![A diagram with the components of AgentKit in an AgentKit
      Network](https://mintlify.s3.us-west-1.amazonaws.com/inngest/graphics/system.svg)
    </Frame>
  </div>
</div>

The entire system is orchestration-aware and allows for customization at runtime for dynamic, powerful AI workflows and agentic systems. Here is what a simple Network looks like in code:

```ts
import {
  createNetwork,
  createAgent,
  openai,
  anthropic,
} from "@inngest/agent-kit";
import { searchWebTool } from "./tools";

const navigator = createAgent({
  name: "Navigator",
  system: "You are a navigator...",
  tools: [searchWebTool],
});

const classifier = createAgent({
  name: "Classifier",
  system: "You are a classifier...",
  model: openai("gpt-3.5-turbo"),
});

const summarizer = createAgent({
  model: anthropic("claude-3-5-haiku-latest"),
  name: "Summarizer",
  system: "You are a summarizer...",
});

const network = createNetwork({
  agents: [navigator, classifier, summarizer],
  defaultModel: openai({ model: "gpt-4o" }),
});

const input = `Classify then summarize the latest 10 blog posts
  on https://www.deeplearning.ai/blog/`;

const result = await network.run(input, ({ network }) => {
  return defaultRoutingAgent;
});
```

## `llms.txt`

You can access the entire AgentKit docs in markdown format at [agentkit.inngest.com/llms-full.txt](https://agentkit.inngest.com/llms-full.txt). This is useful for passing the entire docs to an LLM, AI-enabled IDE, or similar tool to answer questions about AgentKit.

If your context window is too small to pass the entire docs, you can use the shorter [agentkit.inngest.com/llms.txt](https://agentkit.inngest.com/llms.txt) file which offers a table of contents for LLMs or other developer tools to index the docs more easily.


# createAgent
Source: https://agentkit.inngest.com/reference/create-agent

Define an agent

Agents are defined using the `createAgent` function.

```ts
import { createAgent, agenticOpenai as openai } from '@inngest/agent-kit';

const agent = createAgent({
  name: 'Code writer',
  system:
    'You are an expert TypeScript programmer.  Given a set of asks, you think step-by-step to plan clean, ' +
    'idiomatic TypeScript code, with comments and tests as necessary.' +
    'Do not respond with anything else other than the following XML tags:' +
    '- If you would like to write code, add all code within the following tags (replace $filename and $contents appropriately):' +
    "  <file name='$filename.ts'>$contents</file>",
  model: openai('gpt-4o-mini'),
});
```

## Options

<ParamField path="name" type="string" required>
  The name of the agent. Displayed in tracing.
</ParamField>

<ParamField path="description" type="string">
  Optional description for the agent, used for LLM-based routing to help the
  network pick which agent to run next.
</ParamField>

<ParamField path="model" type="string" required>
  The provider model to use for inference calls.
</ParamField>

<ParamField path="system" type="string | function" required>
  The system prompt, as a string or function. Functions let you change prompts
  based off of state and memory.
</ParamField>

<ParamField path="tools" type="array<TypedTool>">
  Defined tools that an agent can call.

  Tools are created via [`createTool`](/reference/createTool).
</ParamField>

<ParamField path="lifecycle" type="Lifecycle">
  Lifecycle hooks that can intercept and modify inputs and outputs throughout the stages of execution of `run()`.

  Learn about each [lifecycle](#lifecycle) hook that can be defined below.
</ParamField>

### `lifecycle`

<ParamField path="onStart" type="function">
  Called after the initial prompt messages are created and before the inference call request. The `onStart` hook can be used to:

  * Modify input prompt for the Agent.
  * Prevent the agent from being called by throwing an error.
</ParamField>

<ParamField path="onResponse" type="function">
  Called after the inference call request is completed and before tool calling. The `onResponse` hook can be used to:

  * Inspect the tools that the model decided to call.
  * Modify the response prior to tool calling.
</ParamField>

<ParamField path="onFinish" type="function">
  Called after tool calling has completed. The `onFinish` hook can be used to:

  * Modify the `InferenceResult` including the outputs prior to the result being added to [Network state](/concepts/network-state).
</ParamField>

<CodeGroup>
  ```ts onStart
  const agent = createAgent({
    name: 'Code writer',
    lifecycles: {
      onStart: ({
        agent,
        network,
        input,
        system, // The system prompt for the agent
        history, // An array of messages
      }) => {
        // Return the system prompt (the first message), and any history added to the
        // model's conversation.
        return { system, history };
      },
    },
  });
  ```

  ```ts onResponse
  function onResponse() {}
  ```
</CodeGroup>

{/* TODO - Add docs for run, withModel, etc. */}


# createNetwork
Source: https://agentkit.inngest.com/reference/create-network

Define a network

Networks are defined using the `createNetwork` function.

```ts
import { createNetwork, openai } from '@inngest/agent-kit';

// Create a network with two agents
const network = createNetwork({
  agents: [searchAgent, summaryAgent],
  defaultModel: openai({ model: 'gpt-4o', step }),
  maxIter: 10,
});
```

## Options

<ParamField path="agents" type="array<Agent>" required>
  Agents that can be called from within the `Network`.
</ParamField>

<ParamField path="defaultModel" type="string">
  The provider model to use for routing inference calls.
</ParamField>

<ParamField path="system" type="string" required>
  The system prompt, as a string or function. Functions let you change prompts
  based off of state and memory
</ParamField>

<ParamField path="tools" type="array<TypedTool>">
  Defined tools that an agent can call.

  Tools are created via [`createTool`](/reference/createTool).
</ParamField>


# createTool
Source: https://agentkit.inngest.com/reference/create-tool

Provide tools to an agent

Tools are defined using the `createTool` function.

```ts
import { createTool } from '@inngest/agent-kit';

const tool = createTool({
  name: 'write-file',
  description: 'Write a file to disk with the given contents',
  parameters: {
    type: 'object',
    properties: {
      path: {
        type: 'string',
        description: 'The path to write the file to',
      },
      contents: {
        type: 'string',
        description: 'The contents to write to the file',
      },
    },
    required: ['path', 'contents'],
  },
  handler: async ({ path, contents }, { agent, network }) => {
    await fs.writeFile(path, contents);
    return { success: true };
  },
});
```

## Options

<ParamField path="name" type="string" required>
  The name of the tool. Used by the model to identify which tool to call.
</ParamField>

<ParamField path="description" type="string" required>
  A clear description of what the tool does. This helps the model understand when and how to use the tool.
</ParamField>

<ParamField path="parameters" type="JSONSchema | ZodType" required>
  A JSON Schema object or Zod type that defines the parameters the tool accepts. This is used to validate the model's inputs and provide type safety.
</ParamField>

<ParamField path="handler" type="function" required>
  The function that executes when the tool is called. It receives the validated parameters as its first argument and a context object as its second argument.
</ParamField>

<ParamField path="strict" type="boolean" default={true}>
  Option to disable strict validation of the tool parameters.
</ParamField>

<ParamField path="lifecycle" type="Lifecycle">
  Lifecycle hooks that can intercept and modify inputs and outputs throughout the stages of tool execution.
</ParamField>

### Handler Function

The handler function receives two arguments:

1. `input`: The validated parameters matching your schema definition
2. `context`: An object containing:
   * `agent`: The Agent instance that called the tool
   * `network`: The network instance, providing access to the [`network.state`](/reference/state).

Example handler with full type annotations:

```ts
import { createTool } from '@inngest/agent-kit';

const tool = createTool({
  name: 'write-file',
  description: 'Write a file to disk with the given contents',
  parameters: {
    type: 'object',
    properties: {
      path: { type: 'string' },
      contents: { type: 'string' },
    },
  },
  handler: async ({ path, contents }, { agent, network }) => {
    await fs.writeFile(path, contents);
    network.state.fileWritten = true;
    return { success: true };
  },
});
```

### `lifecycle`

<ParamField path="onStart" type="function">
  Called before the tool handler is executed. The `onStart` hook can be used to:

  * Modify input parameters before they are passed to the handler
  * Prevent the tool from being called by throwing an error
</ParamField>

<ParamField path="onFinish" type="function">
  Called after the tool handler has completed. The `onFinish` hook can be used to:

  * Modify the result before it is returned to the agent
  * Perform cleanup operations
</ParamField>

<CodeGroup>
  ```ts onStart
  const tool = createTool({
    name: 'write-file',
    lifecycle: {
      onStart: ({ parameters }) => {
        // Validate or modify parameters before execution
        return parameters;
      },
    },
  });
  ```

  ```ts onFinish
  const tool = createTool({
    name: 'write-file',
    lifecycle: {
      onFinish: ({ result }) => {
        // Modify or enhance the result
        return result;
      },
    },
  });
  ```
</CodeGroup>


# Introduction
Source: https://agentkit.inngest.com/reference/introduction

SDK Reference

## Overview

The Inngest Agent Kit is a TypeScript library is divided into two main parts:

<CardGroup>
  <Card title="Agent APIs" href="/reference/create-agent" icon="head-side-gear">
    All the APIs for creating and configuring agents and tools.
  </Card>

  <Card title="Network APIs" href="/reference/create-network" icon="chart-network">
    All the APIs for creating and configuring networks and routers.
  </Card>
</CardGroup>


# Anthropic Model
Source: https://agentkit.inngest.com/reference/model-anthropic

Configure Anthropic as your model provider

The `anthropic` function configures Anthropic's Claude as your model provider.

```ts
import { createAgent, anthropic } from "@inngest/agent-kit";

const agent = createAgent({
  name: "Code writer",
  system: "You are an expert TypeScript programmer.",
  model: anthropic({
    model: "claude-3-opus",
    // Note: max_tokens is required for Anthropic models
    defaultParameters: { max_tokens: 4096 },
  }),
});
```

## Configuration

The `anthropic` function accepts a model name string or a configuration object:

```ts
const agent = createAgent({
  model: anthropic({
    model: "claude-3-opus",
    apiKey: process.env.ANTHROPIC_API_KEY,
    baseUrl: "https://api.anthropic.com/v1/",
    betaHeaders: ["computer-vision"],
    defaultParameters: { temperature: 0.5, max_tokens: 4096 },
  }),
});
```

<Warning>**Note: `defaultParameters.max_tokens` is required.**</Warning>

### Options

<ParamField path="model" type="string" required>
  ID of the model to use. See the [model endpoint
  compatibility](https://docs.anthropic.com/en/docs/about-claude/models) table
  for details on which models work with the Anthropic API.
</ParamField>

<ParamField path="max_tokens" type="number" deprecated>
  **This option has been moved to the `defaultParameters` option.**

  <br />

  The maximum number of tokens to generate before stopping.
</ParamField>

<ParamField path="apiKey" type="string">
  The Anthropic API key to use for authenticating your request. By default we'll
  search for and use the `ANTHROPIC_API_KEY` environment variable.
</ParamField>

<ParamField path="betaHeaders" type="string[]">
  The beta headers to enable, eg. for computer use, prompt caching, and so on.
</ParamField>

<ParamField path="baseUrl" type="string" default="https://api.anthropic.com/v1/">
  The base URL for the Anthropic API.
</ParamField>

<ParamField path="defaultParameters" type="object" required>
  The default parameters to use for the model (ex: `temperature`, `max_tokens`,
  etc).

  <br />

  **Note: `defaultParameters.max_tokens` is required.**
</ParamField>

### Available Models

```plaintext Anthropic
"claude-3-5-haiku-latest"
"claude-3-5-haiku-20241022"
"claude-3-5-sonnet-latest"
"claude-3-5-sonnet-20241022"
"claude-3-5-sonnet-20240620"
"claude-3-opus-latest"
"claude-3-opus-20240229"
"claude-3-sonnet-20240229"
"claude-3-haiku-20240307"
"claude-2.1"
"claude-2.0"
"claude-instant-1.2"
```


# Gemini Model
Source: https://agentkit.inngest.com/reference/model-gemini

Configure Google Gemini as your model provider

The `gemini` function configures Google's Gemini as your model provider.

```ts
import { createAgent, gemini } from "@inngest/agent-kit";

const agent = createAgent({
  name: "Code writer",
  system: "You are an expert TypeScript programmer.",
  model: gemini({ model: "gemini-pro" }),
});
```

## Configuration

The `gemini` function accepts a model name string or a configuration object:

```ts
const agent = createAgent({
  model: gemini({
    model: "gemini-pro",
    apiKey: process.env.GOOGLE_API_KEY,
    baseUrl: "https://generativelanguage.googleapis.com/v1/",
    defaultParameters: {
      generationConfig: {
        temperature: 1.5,
      },
    },
  }),
});
```

### Options

<ParamField path="model" type="string" required>
  ID of the model to use. See the [model endpoint
  compatibility](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini)
  table for details on which models work with the Gemini API.
</ParamField>

<ParamField path="apiKey" type="string">
  The Google API key to use for authenticating your request. By default we'll
  search for and use the `GOOGLE_API_KEY` environment variable.
</ParamField>

<ParamField path="baseUrl" type="string" default="https://generativelanguage.googleapis.com/v1/">
  The base URL for the Gemini API.
</ParamField>

<ParamField path="defaultParameters" type="object">
  The default parameters to use for the model.

  See Gemini's [`models.generateContent` reference](https://ai.google.dev/api/generate-content#method:-models.generatecontent).
</ParamField>

### Available Models

```plaintext Gemini
"gemini-1.5-flash"
"gemini-1.5-flash-8b"
"gemini-1.5-pro"
"gemini-1.0-pro"
"text-embedding-004"
"aqa"
```

For the latest list of available models, see [Google's Gemini model overview](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).

## Limitations

Gemini models do not currently support function without parameters.


# Grok Model
Source: https://agentkit.inngest.com/reference/model-grok

Configure Grok as your model provider

The `grok` function configures Grok as your model provider.

```ts
import { createAgent, grok } from "@inngest/agent-kit";

const agent = createAgent({
  name: "Code writer",
  system: "You are an expert TypeScript programmer.",
  model: grok({ model: "grok-3-latest" }),
});
```

## Configuration

The `grok` function accepts a model name string or a configuration object:

```ts
const agent = createAgent({
  model: grok({
    model: "grok-3-latest",
    apiKey: process.env.XAI_API_KEY,
    baseUrl: "https://api.x.ai/v1",
    defaultParameters: { temperature: 0.5 },
  }),
});
```

### Options

<ParamField path="model" type="string" required>
  ID of the model to use.

  See the [xAI models list](https://docs.x.ai/docs/models).
</ParamField>

<ParamField path="apiKey" type="string">
  The xAI API key to use for authenticating your request. By default we'll
  search for and use the `XAI_API_KEY` environment variable.
</ParamField>

<ParamField path="baseUrl" type="string" default="https://api.x.ai/v1">
  The base URL for the xAI API.
</ParamField>

<ParamField path="defaultParameters" type="object">
  The default parameters to use for the model (ex: `temperature`, `max_tokens`,
  etc).
</ParamField>

### Available Models

```plaintext Gemini
"grok-2-1212"
"grok-2"
"grok-2-latest"
"grok-3"
"grok-3-latest";
```

For the latest list of available models, see [xAI's Grok model overview](https://docs.x.ai/docs/models).

## Limitations

Grok models do not currently support strict function parameters.


# OpenAI Model
Source: https://agentkit.inngest.com/reference/model-openai

Configure OpenAI as your model provider

The `openai` function configures OpenAI as your model provider.

```ts
import { createAgent, openai } from "@inngest/agent-kit";

const agent = createAgent({
  name: "Code writer",
  system: "You are an expert TypeScript programmer.",
  model: openai({ model: "gpt-4" }),
});
```

## Configuration

The `openai` function accepts a model name string or a configuration object:

```ts
const agent = createAgent({
  model: openai({
    model: "gpt-4",
    apiKey: process.env.OPENAI_API_KEY,
    baseUrl: "https://api.openai.com/v1/",
    defaultParameters: { temperature: 0.5 },
  }),
});
```

### Options

<ParamField path="model" type="string" required>
  ID of the model to use. See the [model endpoint
  compatibility](https://platform.openai.com/docs/models#model-endpoint-compatibility)
  table for details on which models work with the Chat API.
</ParamField>

<ParamField path="apiKey" type="string">
  The OpenAI API key to use for authenticating your request. By default we'll
  search for and use the `OPENAI_API_KEY` environment variable.
</ParamField>

<ParamField path="baseUrl" type="string" default="https://api.openai.com/v1/">
  The base URL for the OpenAI API.
</ParamField>

<ParamField path="defaultParameters" type="object">
  The default parameters to use for the model (ex: `temperature`, `max_tokens`,
  etc).
</ParamField>

### Available Models

```plaintext OpenAI
"gpt-4o"
"chatgpt-4o-latest"
"gpt-4o-mini"
"gpt-4"
"o1-preview"
"o1-mini"
"gpt-3.5-turbo"
```


# Network Router
Source: https://agentkit.inngest.com/reference/network-router

Controlling the flow of execution between agents in a Network.

The `defaultRouter` option in `createNetwork` defines how agents are coordinated within a Network. It can be either a [Function Router](#function-router) or a [Routing Agent](#routing-agent).

## Function Router

A function router is provided to the `defaultRouter` option in `createNetwork`.

### Example

```ts
const network = createNetwork({
  agents: [classifier, writer],
  router: ({ lastResult, callCount, network, stack, input }) => {
    // First call: use the classifier
    if (callCount === 0) {
      return classifier;
    }

    // Get the last message from the output
    const lastMessage = lastResult?.output[lastResult?.output.length - 1];
    const content =
      lastMessage?.type === "text" ? (lastMessage?.content as string) : "";

    // Second call: if it's a question, use the writer
    if (callCount === 1 && content.includes("question")) {
      return writer;
    }

    // Otherwise, we're done!
    return undefined;
  },
});
```

### Parameters

<ParamField path="input" type="string">
  The original input provided to the network.
</ParamField>

<ParamField path="network" type="Network">
  The network instance, including its state and history.

  See [`Network.State`](/reference/state) for more details.
</ParamField>

<ParamField path="stack" type="Agent[]">
  The list of future agents to be called. (*internal read-only value*)
</ParamField>

<ParamField path="callCount" type="number">
  The number of agent calls that have been made.
</ParamField>

<ParamField path="lastResult" type="InferenceResult">
  The result from the previously called agent.

  See [`InferenceResult`](/reference/state#inferenceresult) for more details.
</ParamField>

### Return Values

| Return Type    | Description                                        |
| -------------- | -------------------------------------------------- |
| `Agent`        | Single agent to execute next                       |
| `Agent[]`      | Multiple agents to execute in sequence             |
| `RoutingAgent` | Delegate routing decision to another routing agent |
| `undefined`    | Stop network execution                             |

## createRoutingAgent()

Creates a new routing agent that can be used as a `defaultRouter` in a network.

### Example

```ts
import { createRoutingAgent, createNetwork } from "@inngest/agent-kit";

const routingAgent = createRoutingAgent({
  name: "Custom routing agent",
  description: "Selects agents based on the current state and request",
  lifecycle: {
    onRoute: ({ result, network }) => {
      // Get the agent names from the result
      const agentNames = result.output
        .filter((m) => m.type === "text")
        .map((m) => m.content as string);

      // Validate that the agents exist
      return agentNames.filter((name) => network.agents.has(name));
    },
  },
});

// classifier and writer Agents definition...

const network = createNetwork({
  agents: [classifier, writer],
  router: routingAgent,
});
```

### Parameters

<ParamField path="name" type="string" required>
  The name of the routing agent.
</ParamField>

<ParamField path="description" type="string">
  Optional description of the routing agent's purpose.
</ParamField>

<ParamField path="lifecycle" type="object" required>
  <Expandable title="properties">
    <ParamField path="onRoute" type="function" required>
      Called after each inference to determine the next agent(s) to call.

      **Arguments:**

      ```ts
      {
        result: InferenceResult;  // The result from the routing agent's inference
        agent: RoutingAgent;      // The routing agent instance
        network: Network;         // The network instance
      }
      ```

      **Returns:** `string[]` - Array of agent names to call next, or `undefined` to stop execution
    </ParamField>
  </Expandable>
</ParamField>

<ParamField path="model" type="AiAdapter.Any">
  Optional model to use for routing decisions. If not provided, uses the
  network's `defaultModel`.
</ParamField>

### Returns

Returns a `RoutingAgent` instance that can be used as a network's `defaultRouter`.

## Related APIs

* [`createNetwork`](/reference/create-network)
* [`Network.State`](/reference/state)


# createState
Source: https://agentkit.inngest.com/reference/state

Leverage a Network's State across Routers and Agents.

The `State` class provides a way to manage state and history across a network of agents. It includes key-value storage and maintains a stack of all agent interactions.

The `State` is accessible to all Agents, Tools and Routers as a `state` or `network.state` property.

## Creating State

```ts
import { createState } from '@inngest/agent-kit';

export interface NetworkState {
  // username is undefined until extracted and set by a tool
  username?: string;
}

const state = createState<NetworkState>({
  username: 'bar',
});

console.log(state.data.username); // 'bar'


const network = createNetwork({
  // ...
});

// Pass in state to each run
network.run("<query>", { state })
```

## Reading and Modifying State's data (`state.data`)

The `State` class provides typed data accesible via the `data` property.

<Info>
  Learn more about the State use cases in the [State](/docs/concepts/state) concept guide.
</Info>

<ParamField path="data" type="object<T>">
  A standard, mutable object which can be updated and modified within tools.
</ParamField>

## State History

The State history is passed as a `history` to the lifecycle hooks and via the `network` argument to the Tools handlers to the Router function.

The State history can be retrieved *- as a copy -* using the `state.results` property composed of `InferenceResult` objects:

## InferenceResult

The `InferenceResult` class represents a single agent call as part of the network state. It stores all inputs and outputs for a call.

<ParamField path="agent" type="Agent">
  The agent responsible for this inference call.
</ParamField>

<ParamField path="input" type="string">
  The input passed into the agent's run method.
</ParamField>

<ParamField path="prompt" type="Message[]">
  The input instructions without additional history, including the system prompt, user input, and initial agent assistant message.
</ParamField>

<ParamField path="history" type="Message[]">
  The history sent to the inference call, appended to the prompt to form a complete conversation log.
</ParamField>

<ParamField path="output" type="Message[]">
  The parsed output from the inference call.
</ParamField>

<ParamField path="toolCalls" type="ToolResultMessage[]">
  Output from any tools called by the agent.
</ParamField>

<ParamField path="raw" type="string">
  The raw API response from the call in JSON format.
</ParamField>

## `Message` Types

The state system uses several message types to represent different kinds of interactions:

```ts
type Message = TextMessage | ToolCallMessage | ToolResultMessage;

interface TextMessage {
  type: "text";
  role: "system" | "user" | "assistant";
  content: string | Array<TextContent>;
  stop_reason?: "tool" | "stop";
}

interface ToolCallMessage {
  type: "tool_call";
  role: "user" | "assistant";
  tools: ToolMessage[];
  stop_reason: "tool";
}

interface ToolResultMessage {
  type: "tool_result";
  role: "tool_result";
  tool: ToolMessage;
  content: unknown;
  stop_reason: "tool";
}
```


